# ui/vectorstore_tab.py
# -*- coding: utf-8 -*-
import customtkinter as ctk
import tkinter as tk
from tkinter import messagebox
import os
import logging
import threading
import traceback
import re
import json
import config_manager as cm

def build_vectorstore_tab(self):
    """
    æ„å»ºå‘é‡åº“/JSONå­˜å‚¨æ ‡ç­¾é¡µ
    """
    # --- First, add methods to main class to ensure they exist before UI elements are created ---
    self.load_vectorstore_data = load_vectorstore_data.__get__(self)
    self.display_vectorstore_items = display_vectorstore_items.__get__(self)
    self.load_item_content_to_editor = load_item_content_to_editor.__get__(self)
    self.save_vectorstore_item = save_vectorstore_item.__get__(self)
    self.convert_vectorstore_to_markdown = convert_vectorstore_to_markdown.__get__(self) # é‡å‘½åè½¬æ¢æ–¹æ³•
    self.clear_old_data = clear_old_data.__get__(self) # æ–°å¢æ¸…é™¤æ—§æ•°æ®æ–¹æ³•
    self.current_editing_item = None # To store info about the item being edited

    # --- Now, build the UI ---
    self.vectorstore_tab = self.tabview.add("æ•°æ®æŸ¥çœ‹") # æ›´æ”¹æ ‡ç­¾é¡µåç§°
    
    # --- Main Frame ---
    main_frame = ctk.CTkFrame(self.vectorstore_tab)
    main_frame.pack(fill="both", expand=True, padx=5, pady=5)
    main_frame.grid_columnconfigure(0, weight=1)
    main_frame.grid_rowconfigure(1, weight=1) # Display area
    main_frame.grid_rowconfigure(2, weight=2) # Edit area

    # --- Top Button Frame ---
    button_frame = ctk.CTkFrame(main_frame)
    button_frame.grid(row=0, column=0, sticky="ew", padx=5, pady=5)

    self.btn_load_chars = ctk.CTkButton(
        button_frame,
        text="åŠ è½½è§’è‰²çŠ¶æ€",
        command=lambda: self.load_vectorstore_data('character')
    )
    self.btn_load_chars.pack(side="left", padx=5, pady=5)

    self.btn_load_fs = ctk.CTkButton(
        button_frame,
        text="åŠ è½½ä¼ç¬”çŠ¶æ€",
        command=lambda: self.load_vectorstore_data('foreshadowing')
    )
    self.btn_load_fs.pack(side="left", padx=5, pady=5)

    self.btn_save_vs_item = ctk.CTkButton(
        button_frame,
        text="ä¿å­˜ä¿®æ”¹",
        command=self.save_vectorstore_item
    )
    self.btn_save_vs_item.pack(side="left", padx=5, pady=5)

    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ›å»ºæ—§æ•°æ®è¿ç§»ç›¸å…³æŒ‰é’®
    config = cm.load_config()
    if not config.get("hide_old_data_features", False):
        self.btn_convert_vs_to_markdown = ctk.CTkButton(
            button_frame,
            text="è½¬æ¢æ—§é¡¹ç›®ä¸ºMDæ ¼å¼",
            command=self.convert_vectorstore_to_markdown
        )
        self.btn_convert_vs_to_markdown.pack(side="left", padx=10, pady=5)

        self.btn_clear_old_data = ctk.CTkButton(
            button_frame,
            text="æ¸…é™¤æ—§ç‰ˆæ•°æ®",
            command=self.clear_old_data
        )
        self.btn_clear_old_data.pack(side="left", padx=5, pady=5)


    # --- Display Area (Scrollable) ---
    self.vs_display_frame = ctk.CTkScrollableFrame(main_frame, label_text="æ•°æ®å†…å®¹")
    self.vs_display_frame.grid(row=1, column=0, sticky="nsew", padx=5, pady=5)

    # --- Edit Area ---
    self.vs_edit_textbox = ctk.CTkTextbox(main_frame, wrap="word")
    self.vs_edit_textbox.grid(row=2, column=0, sticky="nsew", padx=5, pady=5)

def load_vectorstore_data(self, type):
    """
    åŠ è½½å¹¶æ˜¾ç¤ºè§’è‰²/ä¼ç¬”æ•°æ®ï¼ˆä»Markdownæ–‡ä»¶ï¼‰
    """
    filepath = self.filepath_var.get().strip()
    if not filepath:
        messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©é¡¹ç›®è·¯å¾„")
        return

    def task():
        try:
            self.safe_log(f"æ­£åœ¨åŠ è½½ {type} æ•°æ®...")
            collection_name = "character_state_collection" if type == 'character' else "foreshadowing_collection"
            
            from novel_generator.json_utils import get_store_path, load_store
            md_path = get_store_path(filepath, collection_name)
            
            items = []
            if os.path.exists(md_path):
                self.safe_log(f"  -> ä» {os.path.basename(md_path)} åŠ è½½...")
                data_dict = load_store(filepath, collection_name)
                # è½¬æ¢ä¸ºä¸æ˜¾ç¤ºåŠŸèƒ½å…¼å®¹çš„åˆ—è¡¨æ ¼å¼
                for item_id, data in data_dict.items():
                    items.append({
                        'id': item_id,
                        'document': "N/A", # Documentä¸å†æ˜¯ä¸»è¦æ•°æ®æº
                        'metadata': data
                    })
            else:
                self.safe_log(f"  -> Markdownæ–‡ä»¶ä¸å­˜åœ¨: {os.path.basename(md_path)}")

            if not items:
                self.safe_log(f"æœªèƒ½ä»ä»»ä½•æ¥æºåŠ è½½ {collection_name} çš„å†…å®¹ã€‚")
                self.master.after(0, lambda: self.display_vectorstore_items([], type)) # æ¸…ç©ºæ˜¾ç¤º
                return

            self.master.after(0, lambda: self.display_vectorstore_items(items, type))
            self.safe_log(f"âœ… æˆåŠŸåŠ è½½ {len(items)} æ¡ç›®ã€‚")

        except Exception as e:
            self.handle_exception(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")

    threading.Thread(target=task, daemon=True).start()

def display_vectorstore_items(self, items, type):
    """
    åœ¨UIä¸Šåˆ†ç±»æ˜¾ç¤ºå‘é‡åº“æ¡ç›®
    """
    # Clear previous display
    for widget in self.vs_display_frame.winfo_children():
        widget.destroy()

    if type == 'character':
        # Group by weight
        groups = {
            "ä¸»è§’çº§ (96-100)": [], "æ ¸å¿ƒé…è§’ (81-95)": [], "å…³é”®è§’è‰² (61-80)": [],
            "æ¬¡è¦é…è§’ (41-60)": [], "å•å…ƒè§’è‰² (21-40)": [], "èƒŒæ™¯è§’è‰² (1-20)": [], "æœªåˆ†ç±»": []
        }
        for item in items:
            meta = item.get('metadata', {})
            # ä»JSONåŠ è½½æ—¶ï¼Œæƒé‡åœ¨'åŸºç¡€ä¿¡æ¯' -> 'è§’è‰²æƒé‡'
            base_info = meta.get('åŸºç¡€ä¿¡æ¯', {})
            weight_str = base_info.get('è§’è‰²æƒé‡', '-1')
            
            import re
            weight = -1
            if isinstance(weight_str, str):
                match = re.search(r'\d+', weight_str)
                if match:
                    try:
                        weight = int(match.group(0))
                    except (ValueError, TypeError):
                        weight = -1
            elif isinstance(weight_str, (int, float)):
                weight = int(weight_str)

            if 96 <= weight <= 100: groups["ä¸»è§’çº§ (96-100)"].append(item)
            elif 81 <= weight <= 95: groups["æ ¸å¿ƒé…è§’ (81-95)"].append(item)
            elif 61 <= weight <= 80: groups["å…³é”®è§’è‰² (61-80)"].append(item)
            elif 41 <= weight <= 60: groups["æ¬¡è¦é…è§’ (41-60)"].append(item)
            elif 21 <= weight <= 40: groups["å•å…ƒè§’è‰² (21-40)"].append(item)
            elif 1 <= weight <= 20: groups["èƒŒæ™¯è§’è‰² (1-20)"].append(item)
            else: groups["æœªåˆ†ç±»"].append(item)
        
        # Sort characters within each group by weight descending
        for group in groups.values():
            group.sort(key=lambda x: int(re.search(r'\d+', x.get('metadata', {}).get('åŸºç¡€ä¿¡æ¯', {}).get('è§’è‰²æƒé‡', '-1')).group(0) if re.search(r'\d+', x.get('metadata', {}).get('åŸºç¡€ä¿¡æ¯', {}).get('è§’è‰²æƒé‡', '-1')) else -1), reverse=True)


    elif type == 'foreshadowing':
        # Group by type based on detailed rules
        groups = {
            "ä¸»çº¿ä¼ç¬” (MF)": [], 
            "æš—çº¿ä¼ç¬” (AF)": [], 
            "äººç‰©ä¼ç¬” (CF)": [],
            "æ”¯çº¿ä¼ç¬” (SF)": [], 
            "ä¸€èˆ¬ä¼ç¬” (YF)": [], 
            "å…¶ä»–ä¼ç¬”": []
        }
        for item in items:
            id = item.get('id', '')
            if id.startswith('MF'): groups["ä¸»çº¿ä¼ç¬” (MF)"].append(item)
            elif id.startswith('AF'): groups["æš—çº¿ä¼ç¬” (AF)"].append(item)
            elif id.startswith('CF'): groups["äººç‰©ä¼ç¬” (CF)"].append(item)
            elif id.startswith('SF'): groups["æ”¯çº¿ä¼ç¬” (SF)"].append(item)
            elif id.startswith('YF'): groups["ä¸€èˆ¬ä¼ç¬” (YF)"].append(item)
            else: groups["å…¶ä»–ä¼ç¬”"].append(item)
            
        # Sort foreshadowing within each group by ID
        for group in groups.values():
            group.sort(key=lambda x: x.get('id', ''))

    # Display
    for group_name, group_items in groups.items():
        if not group_items:
            continue
        
        group_frame = ctk.CTkFrame(self.vs_display_frame)
        group_frame.pack(fill="x", pady=(2, 3), padx=5)
        
        label = ctk.CTkLabel(group_frame, text=group_name, font=("Microsoft YaHei", 12, "bold"))
        label.pack(anchor="w", padx=5)
        
        items_frame = ctk.CTkFrame(group_frame)
        items_frame.pack(fill="x", expand=True, pady=2)
        
        row = 0
        col = 0
        # æ¯è¡Œæœ€å¤šæ˜¾ç¤ºçš„æŒ‰é’®æ•°ï¼Œå¯ä»¥æ ¹æ®çª—å£å¤§å°å’ŒæŒ‰é’®å®½åº¦è°ƒæ•´
        max_cols = 9
        for item in group_items:
            meta = item.get('metadata', {})
            id = item.get('id')
            # ä»JSONåŠ è½½æ—¶ï¼Œåç§°é”®æ˜¯'åç§°'
            display_name = meta.get('åç§°', meta.get('name', id)) if type == 'character' else id
            
            btn = ctk.CTkButton(
                items_frame,
                text=display_name,
                command=lambda i=item: self.load_item_content_to_editor(i),
                font=("Microsoft YaHei", 11),
                height=20,
                width=80
            )
            btn.grid(row=row, column=col, padx=3, pady=2)
            
            col += 1
            if col >= max_cols:
                col = 0
                row += 1

def load_item_content_to_editor(self, item):
    """
    å°†é€‰ä¸­æ¡ç›®çš„å†…å®¹æ ¼å¼åŒ–ä¸ºMarkdownå­—ç¬¦ä¸²å¹¶åŠ è½½åˆ°ç¼–è¾‘æ¡†ã€‚
    """
    from novel_generator.json_utils import _json_to_markdown_character, _json_to_markdown_foreshadowing
    self.current_editing_item = item
    
    json_content = item.get('metadata', {})
    if not json_content:
        self.vs_edit_textbox.delete("0.0", "end")
        self.vs_edit_textbox.insert("0.0", "é”™è¯¯ï¼šæœªæ‰¾åˆ°å…ƒæ•°æ®ã€‚")
        return

    try:
        item_type = 'character' if 'åç§°' in json_content else 'foreshadowing'
        if item_type == 'character':
            markdown_content = _json_to_markdown_character(json_content)
        else:
            markdown_content = _json_to_markdown_foreshadowing(json_content)
            
        self.vs_edit_textbox.delete("0.0", "end")
        self.vs_edit_textbox.insert("0.0", markdown_content)
    except Exception as e:
        self.safe_log(f"âŒ æ ¼å¼åŒ–ä¸ºMarkdownæ—¶å‡ºé”™: {e}", level="error")
        self.vs_edit_textbox.delete("0.0", "end")
        self.vs_edit_textbox.insert("0.0", f"æ— æ³•æ ¼å¼åŒ–å†…å®¹: {json_content}")

def save_vectorstore_item(self):
    """
    ä¿å­˜å¯¹æ•°æ®æ¡ç›®çš„ä¿®æ”¹ï¼Œå°†ç¼–è¾‘æ¡†ä¸­çš„Markdownæ–‡æœ¬è§£æä¸ºJSONå¹¶ä¿å­˜ã€‚
    """
    if not self.current_editing_item:
        messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¡ç›®è¿›è¡Œç¼–è¾‘")
        return

    filepath = self.filepath_var.get().strip()
    if not filepath:
        messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©é¡¹ç›®è·¯å¾„")
        return

    modified_markdown = self.vs_edit_textbox.get("0.0", "end-1c").strip()
    item_id = self.current_editing_item.get('id')
    
    meta = self.current_editing_item.get('metadata', {})
    item_type = 'character' if 'åç§°' in meta else 'foreshadowing'
    collection_name = "character_state_collection" if item_type == 'character' else "foreshadowing_collection"

    def task():
        from novel_generator.json_utils import _markdown_to_json, update_item_in_store
        try:
            self.safe_log(f"æ­£åœ¨è§£æå¹¶ä¿å­˜å¯¹ {item_id} çš„ä¿®æ”¹...")
            
            # å°†å•ä¸ªæ¡ç›®çš„Markdownè§£æå›JSONå¯¹è±¡
            # æ³¨æ„ï¼š_markdown_to_jsonæœŸæœ›çš„æ˜¯åŒ…å«æ‰€æœ‰æ¡ç›®çš„å®Œæ•´æ–‡æœ¬ï¼Œ
            # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£æå•ä¸ªæ¡ç›®çš„æ–¹æ³•ã€‚
            # æš‚æ—¶ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªå˜é€šçš„æ–¹æ³•ï¼šç”¨æ•´ä¸ªé›†åˆçš„è§£æå™¨æ¥è§£æå•ä¸ªå—
            parsed_data_dict = _markdown_to_json(modified_markdown, collection_name)
            
            if not parsed_data_dict or item_id not in parsed_data_dict:
                 # å¦‚æœä¸»è¦è§£æå¤±è´¥ï¼Œå°è¯•ä¸€ä¸ªæ›´ç®€å•çš„è¡Œè§£æ
                if item_type == 'character':
                    # å¯¹äºè§’è‰²ï¼Œè§£ææ¯”è¾ƒå¤æ‚ï¼Œå¤±è´¥å¯èƒ½æ€§é«˜ï¼Œæç¤ºç”¨æˆ·æ£€æŸ¥æ ¼å¼
                    raise ValueError("Markdownæ ¼å¼æ— æ³•è¢«æ­£ç¡®è§£æï¼Œè¯·æ£€æŸ¥æ˜¯å¦ç¬¦åˆè§’è‰²æ¨¡æ¿ã€‚")
                else: # ä¼ç¬”çš„ç®€å•è¡Œè§£æ
                    updated_json_data = {}
                    for line in modified_markdown.split('\n'):
                        if ':' in line:
                            key, val = line.split(':', 1)
                            updated_json_data[key.strip()] = val.strip()
            else:
                updated_json_data = parsed_data_dict[item_id]

            if not updated_json_data:
                raise ValueError("Markdownè§£æç»“æœä¸ºç©ºã€‚")

            success = update_item_in_store(filepath, collection_name, item_id, updated_json_data)

            if success:
                self.safe_log(f"âœ… æˆåŠŸæ›´æ–°æ¡ç›® {item_id}")
                # é‡æ–°åŠ è½½æ•°æ®ä»¥åˆ·æ–°UI
                self.master.after(0, lambda: self.load_vectorstore_data(item_type))
            else:
                self.safe_log(f"âŒ æ›´æ–°æ¡ç›® {item_id} å¤±è´¥", level="error")
                messagebox.showerror("ä¿å­˜å¤±è´¥", f"æ— æ³•å°†æ›´æ–°ä¿å­˜åˆ°æ–‡ä»¶ {collection_name}.jsonã€‚")

        except Exception as e:
            self.handle_exception(f"ä¿å­˜æ¡ç›®æ—¶å‡ºé”™: {e}")

    threading.Thread(target=task, daemon=True).start()

def convert_vectorstore_to_markdown(self):
    """
    åŠ è½½æ—§é¡¹ç›®çš„è§’è‰²å’Œä¼ç¬”çŠ¶æ€å‘é‡åº“ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºMarkdownæ–‡ä»¶ä¿å­˜åœ¨å½“å‰é¡¹ç›®ä¸­ã€‚
    """
    from tkinter import filedialog
    from novel_generator.json_utils import save_store
    from embedding_adapters import create_embedding_adapter
    import chromadb
    from chromadb.config import Settings
    from typing import List, Dict, Any

    old_project_path = filedialog.askdirectory(title="è¯·é€‰æ‹©æ—§ç‰ˆé¡¹ç›®çš„æ ¹ç›®å½•")
    if not old_project_path:
        self.safe_log("âŒ ç”¨æˆ·å–æ¶ˆäº†é€‰æ‹©ã€‚")
        return

    def task():
        try:
            self.safe_log(f"ğŸš€ å¼€å§‹ä»æ—§é¡¹ç›®è½¬æ¢æ•°æ®: {old_project_path}")

            # --- Helper functions to load legacy vectorstore ---
            def get_vectorstore_dir(filepath: str, collection_name: str = None) -> str:
                base_dir = os.path.join(filepath, "vectorstore")
                if collection_name: return os.path.join(base_dir, collection_name)
                return base_dir

            def load_vector_store(embedding_adapter, filepath: str, collection_name: str):
                try:
                    store_dir = get_vectorstore_dir(filepath, collection_name)
                    if not os.path.exists(store_dir):
                        logging.info(f"å‘é‡åº“ç›®å½•ä¸å­˜åœ¨: {store_dir}"); return None
                    class EmbeddingFunctionWrapper:
                        def __init__(self, embedding_adapter): self.embedding_adapter = embedding_adapter
                        def __call__(self, input: List[str]) -> List[List[float]]: return self.embedding_adapter.embed_documents(input)
                        def name(self) -> str: return "custom_legacy_embedding_function" # Add name method to satisfy chromadb
                    client = chromadb.PersistentClient(path=store_dir, settings=Settings(anonymized_telemetry=False))
                    return client.get_collection(name=collection_name, embedding_function=EmbeddingFunctionWrapper(embedding_adapter))
                except Exception as e:
                    logging.error(f"åŠ è½½å‘é‡åº“å¤±è´¥: {str(e)}"); traceback.print_exc(); return None

            def get_all_items_from_vectorstore_legacy(store) -> List[Dict[str, Any]]:
                try:
                    all_ids = store.get(include=[])['ids']
                    if not all_ids: return []
                    items = []
                    for i in range(0, len(all_ids), 100):
                        batch_ids = all_ids[i:i + 100]
                        batch_results = store.get(ids=batch_ids, include=["metadatas", "documents"])
                        if not batch_results or not batch_results.get('ids'): continue
                        for j, id in enumerate(batch_results['ids']):
                            items.append({'id': id, 'document': batch_results['documents'][j], 'metadata': batch_results['metadatas'][j]})
                    return items
                except Exception as e:
                    logging.error(f"ä»å‘é‡åº“è·å–æ‰€æœ‰æ¡ç›®æ—¶å‡ºé”™: {e}"); traceback.print_exc(); return []

            embedding_adapter = self.create_embedding_adapter()
            if not embedding_adapter:
                self.safe_log("âŒ æ— æ³•åˆ›å»º Embedding é€‚é…å™¨ï¼Œè½¬æ¢ä¸­æ­¢ã€‚")
                messagebox.showerror("é”™è¯¯", "æ— æ³•åˆ›å»º Embedding é€‚é…å™¨ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
                return

            current_project_path = self.filepath_var.get().strip()
            if not current_project_path:
                messagebox.showerror("é”™è¯¯", "å½“å‰é¡¹ç›®è·¯å¾„æœªè®¾ç½®ï¼Œæ— æ³•ä¿å­˜æ–‡ä»¶ã€‚")
                return

            # --- æ­¥éª¤ 1/2: è½¬æ¢è§’è‰²çŠ¶æ€ ---
            self.safe_log("\n--- æ­¥éª¤ 1/2: è½¬æ¢è§’è‰²çŠ¶æ€ ---")
            def final_perfect_parser(character_block: str) -> dict:
                lines = character_block.strip().split('\n')
                if not lines: return None
                top_level_match = re.match(r'(ID\d+)ï¼š([^\n]+)', lines[0])
                if not top_level_match: return None
                char_id, char_name = top_level_match.group(1), top_level_match.group(2).strip()
                parsed_data = {"ID": char_id, "åç§°": char_name}
                title_pattern = re.compile(r'^([^\n\sï¼š]+)ï¼š', re.MULTILINE)
                matches = list(title_pattern.finditer(character_block))
                for i, match in enumerate(matches):
                    section_title = match.group(1)
                    start_pos = match.end()
                    end_pos = matches[i+1].start() if i + 1 < len(matches) else len(character_block)
                    content_str = character_block[start_pos:end_pos].strip()
                    content_lines = content_str.split('\n')
                    if section_title in ["ä½ç½®è½¨è¿¹", "å…³é”®äº‹ä»¶è®°å½•"]:
                        item_list = []
                        for line in content_lines:
                            line = line.strip().lstrip('-').strip()
                            if not line: continue
                            item_dict = {k.strip(): v.strip() for k, v in re.findall(r'ï¼ˆ([^ï¼š]+)ï¼š([^ï¼‰]+)ï¼‰', line)}
                            main_content = re.sub(r'ï¼ˆ[^ï¼‰]+ï¼‰', '', line).strip()
                            event_match = re.match(r'ç¬¬(\d+)ç« ï¼š\[([^\]]+)\]\s*(.+)', main_content)
                            if event_match:
                                item_dict.update({"ç« èŠ‚": event_match.group(1).strip(), "ç±»å‹": event_match.group(2).strip(), "æ‘˜è¦": event_match.group(3).strip()})
                            elif main_content:
                                item_dict["åœºæ™¯åç§°"] = main_content
                            if item_dict: item_list.append(item_dict)
                        if item_list: parsed_data[section_title] = item_list
                    elif section_title == "å…³ç³»ç½‘":
                        relations = []
                        for line in content_lines:
                            line = line.strip().lstrip('-').strip();
                            if not line: continue
                            parts = re.match(r'([^:]+):\s*([^,]+),å…³ç³»å¼ºåº¦\[([^\]]+)\],äº’åŠ¨é¢‘ç‡\[([^\]]+)\]', line)
                            if parts: relations.append({"å¯¹è±¡": parts.group(1).strip(), "å…³ç³»": parts.group(2).strip(), "å…³ç³»å¼ºåº¦": parts.group(3).strip(), "äº’åŠ¨é¢‘ç‡": parts.group(4).strip()})
                        if relations: parsed_data[section_title] = relations
                    else:
                        kv_data = {}
                        if section_title == "åŠ¿åŠ›ç‰¹å¾":
                            faction_match = re.search(r'åŠ¿åŠ›å½’å±ï¼š\n((?:\s+.*\n?)*)', content_str, re.MULTILINE)
                            if faction_match:
                                nested_content = faction_match.group(1).strip()
                                # Handle full-width spaces for indentation
                                nested_lines = [line.strip().lstrip('â€ƒ').lstrip('-').strip() for line in nested_content.split('\n')]
                                nested_data = {parts[0].strip(): parts[1].strip() for line in nested_lines if 'ï¼š' in line for parts in [line.split('ï¼š', 1)]}
                                kv_data["åŠ¿åŠ›å½’å±"] = nested_data
                                content_str = content_str.replace(faction_match.group(0), '')
                        for line in content_str.split('\n'):
                            line = line.strip()
                            if 'ï¼š' in line:
                                parts = line.split('ï¼š', 1)
                                # Robustly strip leading hyphens and spaces from the key
                                key = re.sub(r'^[-\s]+', '', parts[0]).strip()
                                value = parts[1].strip()
                                if key and value:
                                    kv_data[key] = value
                        if kv_data: parsed_data[section_title] = kv_data
                return parsed_data

            char_collection_name = "character_state_collection"
            self.safe_log(f"ğŸ” æ­£åœ¨ä»æ—§é¡¹ç›® '{char_collection_name}' åŠ è½½å‘é‡åº“...")
            char_store = load_vector_store(embedding_adapter, old_project_path, char_collection_name)
            character_states_json = {}
            char_success = False
            if not char_store: self.safe_log(f"âš ï¸ æœªèƒ½ä»æ—§é¡¹ç›®åŠ è½½è§’è‰²å‘é‡åº“ã€‚")
            else:
                char_items = get_all_items_from_vectorstore_legacy(char_store)
                if not char_items: self.safe_log(f"âš ï¸ æœªèƒ½ä»æ—§é¡¹ç›®åŠ è½½ä»»ä½•è§’è‰²çŠ¶æ€ã€‚")
                else:
                    self.safe_log(f"âœ… æˆåŠŸä»æ—§é¡¹ç›®åŠ è½½ {len(char_items)} æ¡è§’è‰²çŠ¶æ€ã€‚")
                    for item in char_items:
                        parsed_char = final_perfect_parser(item.get('document', ''))
                        if parsed_char: character_states_json[parsed_char["ID"]] = parsed_char
                    if not character_states_json: self.safe_log("âŒ åŠ è½½çš„è§’è‰²æ•°æ®ä¸­æ— æ³•è§£æå‡ºä»»ä½•æœ‰æ•ˆæ¡ç›®ã€‚")
                    else:
                        if save_store(current_project_path, char_collection_name, character_states_json):
                            self.safe_log(f"ğŸ‰ æˆåŠŸè½¬æ¢ {len(character_states_json)} æ¡è§’è‰²çŠ¶æ€åˆ°Markdownã€‚")
                            char_success = True
                        else: self.safe_log("âŒ ä¿å­˜è§’è‰²çŠ¶æ€Markdownæ–‡ä»¶å¤±è´¥", level="error")

            # --- æ­¥éª¤ 2/2: è½¬æ¢ä¼ç¬”çŠ¶æ€ ---
            self.safe_log("\n--- æ­¥éª¤ 2/2: è½¬æ¢ä¼ç¬”çŠ¶æ€ ---")
            # This function is now designed to parse the entire item dictionary from the vectorstore,
            # not just the document text.
            def parse_foreshadowing_document(item: dict) -> dict:
                """
                The definitive parser based on direct analysis of the complete vectorstore item,
                including both document and metadata.
                """
                if not isinstance(item, dict):
                    return None

                doc_text = item.get('document', '').strip()
                metadata = item.get('metadata', {})
                item_id = item.get('id', '').strip()

                # æ¸…é™¤IDæœ«å°¾å¯èƒ½å­˜åœ¨çš„ "_æ•°å­—" åç¼€
                item_id = re.sub(r'_\d+$', '', item_id)

                # The ID from the top level is the most reliable.
                if not item_id:
                    return None
                
                # The content is the entire document text.
                if not doc_text:
                    return None
                    
                parsed_data = {
                    "ID": item_id,
                    "å†…å®¹": doc_text
                }

                # The last chapter is in the metadata.
                last_chapter = metadata.get('ä¼ç¬”æœ€åç« èŠ‚')
                if last_chapter:
                    parsed_data['ä¼ç¬”æœ€åç« èŠ‚'] = last_chapter.strip()
                
                return parsed_data

            fs_collection_name = "foreshadowing_collection"
            self.safe_log(f"ğŸ” æ­£åœ¨ä»æ—§é¡¹ç›® '{fs_collection_name}' åŠ è½½å‘é‡åº“...")
            fs_store = load_vector_store(embedding_adapter, old_project_path, fs_collection_name)
            foreshadowing_json = {}
            fs_success = False
            if not fs_store: self.safe_log(f"âš ï¸ æœªèƒ½ä»æ—§é¡¹ç›®åŠ è½½ä¼ç¬”å‘é‡åº“ã€‚")
            else:
                fs_items = get_all_items_from_vectorstore_legacy(fs_store)
                if not fs_items: self.safe_log(f"âš ï¸ æœªèƒ½ä»æ—§é¡¹ç›®åŠ è½½ä»»ä½•ä¼ç¬”çŠ¶æ€ã€‚")
                else:
                    self.safe_log(f"âœ… æˆåŠŸä»æ—§é¡¹ç›®åŠ è½½ {len(fs_items)} æ¡ä¼ç¬”çŠ¶æ€ã€‚")
                    for item in fs_items:
                        # Pass the entire item dictionary to the new parser
                        parsed_fs = parse_foreshadowing_document(item)
                        if parsed_fs: foreshadowing_json[parsed_fs["ID"]] = parsed_fs
                    if not foreshadowing_json: self.safe_log("âŒ åŠ è½½çš„ä¼ç¬”æ•°æ®ä¸­æ— æ³•è§£æå‡ºä»»ä½•æœ‰æ•ˆæ¡ç›®ã€‚")
                    else:
                        if save_store(current_project_path, fs_collection_name, foreshadowing_json):
                            self.safe_log(f"ğŸ‰ æˆåŠŸè½¬æ¢ {len(foreshadowing_json)} æ¡ä¼ç¬”çŠ¶æ€åˆ°Markdownã€‚")
                            fs_success = True
                        else: self.safe_log("âŒ ä¿å­˜ä¼ç¬”çŠ¶æ€Markdownæ–‡ä»¶å¤±è´¥", level="error")

            # --- Final Summary ---
            if char_success or fs_success:
                msg = "æ•°æ®è½¬æ¢å®Œæˆï¼\n\n"
                if char_success: msg += f"è§’è‰²çŠ¶æ€: æˆåŠŸè½¬æ¢ {len(character_states_json)} æ¡\n"
                else: msg += "è§’è‰²çŠ¶æ€: è½¬æ¢å¤±è´¥æˆ–æ— æ•°æ®\n"
                if fs_success: msg += f"ä¼ç¬”çŠ¶æ€: æˆåŠŸè½¬æ¢ {len(foreshadowing_json)} æ¡"
                else: msg += "ä¼ç¬”çŠ¶æ€: è½¬æ¢å¤±è´¥æˆ–æ— æ•°æ®"
                messagebox.showinfo("è½¬æ¢æˆåŠŸ", msg)
            else:
                messagebox.showwarning("è½¬æ¢å®Œæˆ", "æœªæ‰¾åˆ°ä»»ä½•å¯è½¬æ¢çš„æ—§ç‰ˆæ•°æ®ã€‚")

        except Exception as e:
            self.handle_exception(f"è½¬æ¢æ—§é¡¹ç›®æ•°æ®æ—¶å‡ºé”™: {e}")
            messagebox.showerror("è½¬æ¢å¤±è´¥", f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:\n{e}")

    threading.Thread(target=task, daemon=True).start()

def clear_old_data(self):
    """
    æ°¸ä¹…æ€§åœ°æ¸…é™¤ä¸æ—§ç‰ˆå‘é‡åº“ç›¸å…³çš„æ•°æ®å’ŒUIå…ƒç´ ï¼Œå¹¶ä¿å­˜è®¾ç½®ã€‚
    """
    if messagebox.askyesno("ç¡®è®¤æ“ä½œ", "æ­¤æ“ä½œå°†æ°¸ä¹…ç§»é™¤æ—§ç‰ˆæ•°æ®ç›¸å…³åŠŸèƒ½ï¼Œé‡å¯åç”Ÿæ•ˆï¼Œä¸”ä¸å¯é€†ï¼Œç¡®å®šè¦ç»§ç»­å—ï¼Ÿ"):
        try:
            self.safe_log("æ­£åœ¨æ¸…é™¤æ—§ç‰ˆæ•°æ®ç›¸å…³åŠŸèƒ½...")

            # 1. æ›´æ–°å¹¶ä¿å­˜é…ç½®
            config = cm.load_config()
            config["hide_old_data_features"] = True

            # éå†æ‰€æœ‰ç°æœ‰é…ç½®ï¼Œåˆ é™¤å…¶ä¸­çš„ embedding_config
            if "configurations" in config:
                for conf_name, conf_data in config["configurations"].items():
                    if "embedding_config" in conf_data:
                        del conf_data["embedding_config"]
                        self.safe_log(f"  -> å·²ä»é…ç½® '{conf_name}' ä¸­ç§»é™¤åµŒå…¥æ¨¡å‹è®¾ç½®ã€‚")

            cm.save_config(config)
            self.safe_log("  -> å·²æ›´æ–°å¹¶æ¸…ç†é…ç½®æ–‡ä»¶ï¼Œå°†åœ¨ä¸‹æ¬¡å¯åŠ¨æ—¶éšè—æ—§åŠŸèƒ½ã€‚")

            # 2. åœ¨å½“å‰ä¼šè¯ä¸­ç§»é™¤UIå…ƒç´ 
            if hasattr(self, 'btn_convert_vs_to_markdown'):
                self.btn_convert_vs_to_markdown.pack_forget()
                self.safe_log("  -> å·²éšè— 'è½¬æ¢æ—§é¡¹ç›®ä¸ºMDæ ¼å¼' æŒ‰é’®ã€‚")

            if hasattr(self, 'btn_clear_old_data'):
                self.btn_clear_old_data.pack_forget()
                self.safe_log("  -> å·²éšè— 'æ¸…é™¤æ—§ç‰ˆæ•°æ®' æŒ‰é’®ã€‚")

            # 3. æ­£ç¡®åœ°ç§»é™¤ Embedding æ¨¡å‹è®¾ç½®æ ‡ç­¾é¡µ
            if hasattr(self, 'llm_embedding_tabview'):
                try:
                    # ä½¿ç”¨CTabViewçš„deleteæ–¹æ³•æ¥ç§»é™¤æ ‡ç­¾é¡µ
                    self.llm_embedding_tabview.delete("Embedding æ¨¡å‹è®¾ç½®")
                    self.safe_log("  -> å·²ç§»é™¤ 'Embedding æ¨¡å‹è®¾ç½®' æ ‡ç­¾é¡µã€‚")
                except Exception as tab_error:
                    self.safe_log(f"  -> ç§»é™¤ 'Embedding æ¨¡å‹è®¾ç½®' æ ‡ç­¾é¡µæ—¶å‘ç”Ÿé”™è¯¯: {tab_error}", level="warning")
            else:
                self.safe_log("  -> æœªæ‰¾åˆ° 'llm_embedding_tabview' æ§ä»¶ï¼Œæ— æ³•ç§»é™¤æ ‡ç­¾é¡µã€‚", level="warning")

            self.safe_log("âœ… æ¸…é™¤æ“ä½œå®Œæˆã€‚")
            messagebox.showinfo("å®Œæˆ", "æ—§ç‰ˆæ•°æ®ç›¸å…³åŠŸèƒ½å·²æ ‡è®°ä¸ºç§»é™¤ã€‚è¯·é‡å¯è½¯ä»¶ä»¥ä½¿æ‰€æœ‰æ›´æ”¹å®Œå…¨ç”Ÿæ•ˆã€‚")

        except Exception as e:
            self.handle_exception(f"æ¸…é™¤æ—§ç‰ˆæ•°æ®æ—¶å‡ºé”™: {e}")
            messagebox.showerror("é”™è¯¯", f"æ¸…é™¤æ“ä½œå¤±è´¥:\n{e}")
